{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 3 HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPjk85X8lJzySbRbVD0W1F2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikvas6/NN/blob/master/Lesson_3_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYOqtXBb3Ex",
        "colab_type": "code",
        "outputId": "1bcae3eb-71b1-46e7-93a2-a0e68d888d41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJZyNZNcABJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    # Use the version pre-encoded with an ~8k vocabulary.\n",
        "    'imdb_reviews/subwords8k', \n",
        "    # Return the train/test datasets as a tuple.\n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "    # Return (example, label) pairs from the dataset (instead of a dictionary).\n",
        "    as_supervised=True,\n",
        "    # Also return the `info` structure. \n",
        "    with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG7tw1w0NvdF",
        "colab_type": "text"
      },
      "source": [
        "Данные изначально представляют из себя набор отзыв - его бинарная оценка (положительный или отрцательный), при этом отзыв написан на человеческом языке, и его сначала надо токенизировать. В imdb_reviews есть несколько датасетов, и датасеты subwords8k и subwords32k содержат в себе уже токенизированные данные (с разным объёмом словаря). Я нашёл в документации разбор датасета subwords8k, поэтому взял его."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrEW-4XrcIHu",
        "colab_type": "code",
        "outputId": "d5eafd27-c1ec-4f4f-db30-38d4275f6dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.data.experimental.cardinality(train_data)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=25000>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE7rYt7jOogv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "a27e55a2-6fe8-47ac-a64b-d25ebc4cc3e6"
      },
      "source": [
        "for data_example, label_example in train_data.take(1):\n",
        "    print(data_example)\n",
        "    print(label_example)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[  62   18   41  604  927   65    3  644 7968   21   35 5096   36   11\n",
            "   43 2948 5240  102   50  681 7862 1244    3 3266   29  122  640    2\n",
            "   26   14  279  438   35   79  349  384   11 1991    3  492   79  122\n",
            "  188  117   33 4047 4531   14   65 7968    8 1819 3947    3   62   27\n",
            "    9   41  577 5044 2629 2552 7193 7961 3642    3   19  107 3903  225\n",
            "   85  198   72    1 1512  738 2347  102 6245    8   85  308   79 6936\n",
            " 7961   23 4981 8044    3 6429 7961 1141 1335 1848 4848   55 3601 4217\n",
            " 8050    2    5   59 3831 1484 8040 7974  174 5773   22 5240  102   18\n",
            "  247   26    4 3903 1612 3902  291   11    4   27   13   18 4092 4008\n",
            " 7961    6  119  213 2774    3   12  258 2306   13   91   29  171   52\n",
            "  229    2 1245 5790  995 7968    8   52 2948 5240 8039 7968    8   74\n",
            " 1249    3   12  117 2438 1369  192   39 7975], shape=(163,), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT1f3ESRcTml",
        "colab_type": "code",
        "outputId": "e66600f2-7cc2-44c1-aa66-5a80f2ecb7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.data.experimental.cardinality(test_data)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=25000>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ-0O3B4QTNl",
        "colab_type": "text"
      },
      "source": [
        "Из датасета мы взяли так же метаинформацию о нём, которая в том числе содержит словарь, который использовался для токенизации датасета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS5Mpmr-ceF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "447cda23-d461-4e9e-8b4b-cdc58e0f4a89"
      },
      "source": [
        "info"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='imdb_reviews',\n",
              "    version=1.0.0,\n",
              "    description='Large Movie Review Dataset.\n",
              "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
              "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "    features=FeaturesDict({\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "        'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
              "    }),\n",
              "    total_num_examples=100000,\n",
              "    splits={\n",
              "        'test': 25000,\n",
              "        'train': 25000,\n",
              "        'unsupervised': 50000,\n",
              "    },\n",
              "    supervised_keys=('text', 'label'),\n",
              "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "      month     = {June},\n",
              "      year      = {2011},\n",
              "      address   = {Portland, Oregon, USA},\n",
              "      publisher = {Association for Computational Linguistics},\n",
              "      pages     = {142--150},\n",
              "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhIPCBpncx0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-vm76CDcznR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcfa75c7-0dda-4b3a-888d-ed65b48cf5a9"
      },
      "source": [
        "print ('Vocabulary size: {}'.format(encoder.vocab_size))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 8185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqfVKmjURFjv",
        "colab_type": "text"
      },
      "source": [
        "Разобьём данные на батчи, причём используем функцию padded_batch, благодаря чему в каждом батче длина отзывов будет одинаковая - в человеческом языке предложения имеют разную длину, что неудобно при обучении модели, поэтому данные лучше выравнить, добивая каким-нибудь нулевым символом размер предложения до выбранного значения. Вообще padded_batch пока не решит нашу проблему, т.к. эта функция ровняет только батч, в дальнейшем мы воспользуемся специальным слоем в сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5kLAQ5WQ28Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "train_batches = (\n",
        "    train_data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32))\n",
        "\n",
        "test_batches = (\n",
        "    test_data\n",
        "    .padded_batch(32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viuz7oRnRD9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "298751a2-5301-4614-9496-3ffcef9462eb"
      },
      "source": [
        "for example_batch, label_batch in train_batches.take(2):\n",
        "  print(\"Batch shape:\", example_batch.shape)\n",
        "  print(\"label shape:\", label_batch.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape: (32, 805)\n",
            "label shape: (32,)\n",
            "Batch shape: (32, 768)\n",
            "label shape: (32,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jalAKnNwRkko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "46226edd-68f5-48b5-8d37-a68ca26321bb"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(64),\n",
        "  keras.layers.Dense(1)])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 132,113\n",
            "Trainable params: 132,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMesi905RqAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9ND9KwjSP8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "87346189-fd17-4976-eafc-f9e252315210"
      },
      "source": [
        "model.fit(train_batches,\n",
        "            epochs=10,\n",
        "            validation_data=test_batches,\n",
        "            validation_steps=30)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.5506 - accuracy: 0.6581 - val_loss: 0.4262 - val_accuracy: 0.8448\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.2959 - accuracy: 0.8764 - val_loss: 0.3537 - val_accuracy: 0.8656\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.2335 - accuracy: 0.9065 - val_loss: 0.4131 - val_accuracy: 0.8146\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1998 - accuracy: 0.9202 - val_loss: 0.3810 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1793 - accuracy: 0.9286 - val_loss: 0.4725 - val_accuracy: 0.8552\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1577 - accuracy: 0.9391 - val_loss: 0.4299 - val_accuracy: 0.8635\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1442 - accuracy: 0.9442 - val_loss: 0.4658 - val_accuracy: 0.8573\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1303 - accuracy: 0.9494 - val_loss: 0.5061 - val_accuracy: 0.8521\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1177 - accuracy: 0.9537 - val_loss: 0.5529 - val_accuracy: 0.8500\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.1084 - accuracy: 0.9590 - val_loss: 0.6023 - val_accuracy: 0.8531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0bf6297be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jed2Kp6WSW49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "686f5305-090c-4b9b-bb8d-70a7d1234be2"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 4s 6ms/step - loss: 0.5605 - accuracy: 0.8606\n",
            "Loss:  0.5604603290557861\n",
            "Accuracy:  0.8605999946594238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfkuonGfSg6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}